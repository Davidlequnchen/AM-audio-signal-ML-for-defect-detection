{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e151958-ed8c-4401-a79f-ce1ffcbb36c1",
   "metadata": {},
   "source": [
    "# Acoustic signal feature extraction\n",
    "### Notebook 4: Feature extraction for ML\n",
    "- Authorï¼š Chen Lequn\n",
    "- Experiment date: __June__\n",
    "- Extraction of key acoustic features for training traditional ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377af664-98aa-4748-9213-f6a616af8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Required python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from skimage.transform import resize\n",
    "\n",
    "## Audio signal processing libraries\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "# ------------------- plotly visualizatoin----------------------------------\n",
    "from PIL import Image\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from skimage import data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Use grid search with cross validation to select ML model hyper-parameters:\n",
    "from sklearn.model_selection import train_test_split  # random split the data into \"training data\" and \"testing data\"\n",
    "from sklearn.model_selection import GridSearchCV  # Exhaustive grid search with cross validation (CV)\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import scaleogram as scg \n",
    "from glob import glob\n",
    "import glob\n",
    "import re\n",
    "import scipy\n",
    "from scipy.signal import welch\n",
    "import wave                    # library handles the parsing of WAV file headers\n",
    "import pywt\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094254fd-2361-4af6-8b24-96e46bc3e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "plt.rcParams[\"axes.linewidth\"] = 2.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659a2795-f339-4ded-be09-7a3dbf48c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch libraryes and torchaudio - for GPU accelerated feature extraction\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchsummary import summary\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import nussl\n",
    "import natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519a9c9-aeeb-4704-a7e4-c74114dc3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures, and dataset locations\n",
    "PROJECT_ROOT_DIR = \"../\"\n",
    "Audio_PATH_original = os.path.join(PROJECT_ROOT_DIR, \"AM_audio_dataset\", 'AMDataset_v4_June_Experiment', 'wave_file', \"original\", 'train')\n",
    "Audio_PATH_original_seg = os.path.join(PROJECT_ROOT_DIR, \"AM_audio_dataset\", 'AMDataset_v4_June_Experiment', 'wave_file', \"original\", \"train_seg\")\n",
    "Audio_PATH_equalized = os.path.join(PROJECT_ROOT_DIR, \"AM_audio_dataset\", 'AMDataset_v4_June_Experiment', 'wave_file', \"equalized\")\n",
    "Audio_PATH_bandpassed = os.path.join(PROJECT_ROOT_DIR, \"AM_audio_dataset\", 'AMDataset_v4_June_Experiment', 'wave_file', \"bandpassed\")\n",
    "Audio_PATH_denoised = os.path.join(PROJECT_ROOT_DIR, \"AM_audio_dataset\", 'AMDataset_v4_June_Experiment', 'wave_file', \"denoised\", 'train')\n",
    "\n",
    "Audio_PATH_original_layer = os.path.join(PROJECT_ROOT_DIR, \"AM_audio_dataset\", 'AMDataset_v4_June_Experiment', 'wave_file', \"original\", \"sliced_layers\")\n",
    "Audio_PATH_equalized_layer = os.path.join(PROJECT_ROOT_DIR, \"AM_audio_dataset\", 'AMDataset_v4_June_Experiment', 'wave_file', \"equalized\", \"sliced_layers\")\n",
    "Audio_PATH_bandpass_layer = os.path.join(PROJECT_ROOT_DIR, \"AM_audio_dataset\", 'AMDataset_v4_June_Experiment', 'wave_file', \"bandpassed\", \"sliced_layers\")\n",
    "Audio_PATH_denoised_layer = os.path.join(PROJECT_ROOT_DIR, \"AM_audio_dataset\", 'AMDataset_v4_June_Experiment', 'wave_file', \"denoised\", \"sliced_layers\")\n",
    "\n",
    "label_file = os.path.join(PROJECT_ROOT_DIR, \"AM_audio_dataset\", 'AMDataset_v4_June_Experiment', 'wave_file', 'label.csv')\n",
    "\n",
    "Experiment_PATH = os.path.join(PROJECT_ROOT_DIR, \"AM_audio_dataset\", 'AMDataset_v4_June_Experiment')\n",
    "IMAGE_PATH = os.path.join(PROJECT_ROOT_DIR, \"result_images\", 'AMDataset_v4_June_Experiment', \"Dataset_analysis\")\n",
    "os.makedirs(Audio_PATH_original, exist_ok=True)\n",
    "os.makedirs(Audio_PATH_original_seg, exist_ok=True)\n",
    "os.makedirs(IMAGE_PATH, exist_ok=True)\n",
    "\n",
    "## function for automatically save the diagram/graph into the folder \n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGE_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1abf81c-a6f4-4c9d-91f4-34c1f955f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../utils')\n",
    "\n",
    "import utils\n",
    "import utils_June_exp\n",
    "import filter\n",
    "import feature_extractions\n",
    "from feature_extractions import amplitude_envelope\n",
    "FRAME_SIZE = 2048\n",
    "HOP_LENGTH = 512\n",
    "from scipy.fftpack import fft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfec8be-f751-404b-8af0-d6c03e29628a",
   "metadata": {},
   "source": [
    "## Load label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c14c1-7b9f-42bd-acb4-30a074a1e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(label_file)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa4400d-1f67-40da-8680-a2f068035cb3",
   "metadata": {},
   "source": [
    "## Load audio data (layer-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eca435-782d-432f-83d4-8a9d2eb7e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AM_wav_original = glob.glob1(Audio_PATH_original_layer, '*.wav')\n",
    "AM_wav_original = natsort.natsorted(AM_wav_original)\n",
    "for i in range(len(AM_wav_original)):\n",
    "    AM_wav_original[i]= Audio_PATH_original_layer + \"\\\\\" + AM_wav_original[i]\n",
    "print(f'Total wav file in Audio_PATH_original_layer folder :{len(AM_wav_original)}')\n",
    "\n",
    "\n",
    "AM_wav_equalized = glob.glob1(Audio_PATH_equalized_layer, '*.wav')\n",
    "AM_wav_equalized = natsort.natsorted(AM_wav_equalized)\n",
    "for i in range(len(AM_wav_equalized)):\n",
    "    AM_wav_equalized[i]= Audio_PATH_equalized_layer + \"\\\\\" + AM_wav_equalized[i]\n",
    "print(f'Total wav file in Audio_PATH_equalized_layer folder :{len(AM_wav_equalized)}')\n",
    "\n",
    "\n",
    "AM_wav_bandpass = glob.glob1(Audio_PATH_bandpass_layer, '*.wav')\n",
    "AM_wav_bandpass = natsort.natsorted(AM_wav_bandpass)\n",
    "for i in range(len(AM_wav_bandpass)):\n",
    "    AM_wav_bandpass[i]= Audio_PATH_bandpass_layer + \"\\\\\" + AM_wav_bandpass[i]\n",
    "print(f'Total wav file in Audio_PATH_bandpass_layer folder :{len(AM_wav_bandpass)}')\n",
    "\n",
    "\n",
    "AM_wav_denoised = glob.glob1(Audio_PATH_denoised_layer, '*.wav')\n",
    "AM_wav_denoised = natsort.natsorted(AM_wav_denoised)\n",
    "for i in range(len(AM_wav_denoised)):\n",
    "    AM_wav_denoised[i]= Audio_PATH_denoised_layer + \"\\\\\" + AM_wav_denoised[i]\n",
    "    \n",
    "print(f'Total wav file in Audio_PATH_denoised_layer folder :{len(AM_wav_denoised)}')\n",
    "\n",
    "\n",
    "dataset_original = []\n",
    "dataset_equalized = []\n",
    "dataset_bandpassed= []\n",
    "dataset_denoised = []\n",
    "\n",
    "\n",
    "def generate_structured_datset(files, dataset_name):\n",
    "    for file in files:\n",
    "        # exp_25_denoised_layer_28.wav\n",
    "        # experiment number is second (1) position, layer number is 4 position, category (denoised/original) is position 2\n",
    "        experiment_number = int(os.path.basename(file).split(\"_\")[1])  \n",
    "        layer_number_wav = os.path.basename(file).split(\"_\")[4]\n",
    "        separator = '.'\n",
    "        layer_number = int(layer_number_wav.split(separator, 1)[0])\n",
    "        # slice_number = os.path.basename(file).split(\"_\")[5]\n",
    "        signal_category = os.path.basename(file).split(\"_\")[2]\n",
    "        filename = os.path.basename(file)\n",
    "        filepath = file\n",
    "        dur = librosa.get_duration(filename = file)\n",
    "        signal = librosa.load(file, sr=None)[0]\n",
    "        # compile label wav\n",
    "        dataset_name.append({'filename': filename,\n",
    "                                 'wav_duration' : dur,\n",
    "                                 'file_path' : filepath,\n",
    "                                 'Sample' : experiment_number,\n",
    "                                 'layer' : layer_number,\n",
    "                                 'signal_category' : signal_category,\n",
    "                                 'signal': signal,\n",
    "                                })\n",
    "    print (\"dataset created\")\n",
    "        \n",
    "generate_structured_datset(AM_wav_original, dataset_original)\n",
    "generate_structured_datset(AM_wav_equalized, dataset_equalized)\n",
    "generate_structured_datset(AM_wav_bandpass, dataset_bandpassed)\n",
    "generate_structured_datset(AM_wav_denoised, dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d78d27-35c4-41d3-8f50-de04419f94ff",
   "metadata": {},
   "source": [
    "### convert dataset into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26632cfe-5c08-4597-910c-417a6839b1b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### convert AM_dataset into dataframe\n",
    "df_dataset_original = pd.DataFrame(dataset_original)\n",
    "df_dataset_equalized = pd.DataFrame(dataset_equalized)\n",
    "df_dataset_bandpassed = pd.DataFrame(dataset_bandpassed)\n",
    "df_dataset_denoised = pd.DataFrame(dataset_denoised)\n",
    "\n",
    "print(f'df_dataset_original : {df_dataset_original.shape}')\n",
    "print(f'df_dataset_equalized : {df_dataset_equalized.shape}')\n",
    "print(f'df_dataset_bandpassed : {df_dataset_bandpassed.shape}')\n",
    "print(f'df_dataset_denoised : {df_dataset_denoised.shape}')\n",
    "\n",
    "df_dataset_denoised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb65b6f-80d1-41b5-8572-a7f4c2ea4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df_dataset_original[\"file_path\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff011c-f442-41d9-ab0f-c2d587e5bb2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dataset_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48cc8c7-1eaf-4eaa-855e-2af08518d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_original = pd.merge(df_dataset_original, labels)\n",
    "df_dataset_equalized = pd.merge(df_dataset_equalized, labels)\n",
    "df_dataset_bandpassed = pd.merge(df_dataset_bandpassed, labels)\n",
    "df_dataset_denoised = pd.merge(df_dataset_denoised, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276cc6ca-4b46-4dd3-8fab-e594477ee54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6721b79-7b3c-4297-9556-37cd952c44cb",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e763e-7007-4f9b-b47a-e4373eba85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce11fbc-e46e-4322-9bbe-24da4b08ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df_dataset_denoised['Label'].unique() # five unique labels\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcf19c6-5d2d-4590-a472-cc2f35a3e406",
   "metadata": {},
   "source": [
    "### Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f22dc-fa90-4d20-8d4c-90d1f4df315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize = (7,6))\n",
    "\n",
    "\n",
    "ax = sns.countplot(x='Label', data = df_dataset_denoised, palette=\"Set1\"); #palette='mako' 'Set2'\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "# ax = sns.countplot(y='label', data = df_dataset_denoised, palette=\"Set2\");\n",
    "\n",
    "\n",
    "ax.set_title('Distribution of AM audio signal per category', fontsize = 18);\n",
    "ax.set_xlabel(\"Experiment number\",fontsize=18, labelpad=10)\n",
    "ax.set_ylabel(\"Count\",fontsize=18, labelpad=10)\n",
    "ax.tick_params(labelsize=15)\n",
    "\n",
    "save_fig(\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c9e7b-6120-4d2b-8124-e0f9fdfcb9b4",
   "metadata": {},
   "source": [
    "### Ramdon checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815930b-2469-4529-adff-70de042a7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal, sr = librosa.load(AM_wav_denoised[20], sr=None)\n",
    "signal = df_dataset_equalized.signal[20]\n",
    "utils.simple_visualization(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8f145-a419-4af0-ab38-3df55bce2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mfcc feature\n",
    "mfccs = librosa.feature.mfcc(y =signal, sr = 44100, n_mfcc = 20)\n",
    "\n",
    "img=librosa.display.specshow(mfccs, \n",
    "                            sr=44100, \n",
    "                            hop_length=256, \n",
    "                            x_axis=\"time\", \n",
    "                            y_axis='log',\n",
    "                            # cmap=cmap, #'viridis', 'plasma', 'inferno', 'magma', 'cividis', 'jet'\n",
    "                            # vmin = vmin, vmax = vmax\n",
    "                            )\n",
    "# plt.colorbar(img, format=\"%+5.f dB\")\n",
    "# plt.colorbar(img)\n",
    "plt.title(\"MFCC\", fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize = 16)\n",
    "plt.xlabel('Time', fontsize = 16)  #(Î¼s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972868bf-585c-4699-8cc1-f7721e669797",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_magnitude_spectrum_single(signal, 44100, \"FFT\", log_y=True, log_x = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f49713-9e76-48c0-b490-8451d7eda2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractions.visualize_rms_smooth([signal],FRAME_SIZE,HOP_LENGTH, 44100, N_smooth = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9f5b56-7d0f-462d-a115-d32d82c090e8",
   "metadata": {},
   "source": [
    "# Feature extraction for traditional ML\n",
    "\n",
    "- Time-domain features:\n",
    "    - Amplitude envolope (AE)\n",
    "    - RMS Energy\n",
    "    - zero crossing rate\n",
    "- Frequency domain features:\n",
    "    - band energy ratio (BER)\n",
    "\n",
    "- time-freqeuncy features:\n",
    "    - Spectral centroid (frequency-domain feature)\n",
    "    - Spectral bandwdith\n",
    "    - Spectral flatness\n",
    "    - Spectral rolloff 85%\n",
    "    - Spectral contrast\n",
    "    - Spectral variance\n",
    "    - Spectral Crest\n",
    "    - Spectral Skewness\n",
    "    - Spectral Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef34f4f-f96a-48ca-9cf6-98e71a72c802",
   "metadata": {},
   "source": [
    "### AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd47d1-9a09-4466-b2aa-0fb6a2bd02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ae_feature(df_dataset_sound):\n",
    "    ae_list = []\n",
    "    ae_mean_list = []\n",
    "    ae_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        ae = amplitude_envelope(sample_data, FRAME_SIZE, HOP_LENGTH)\n",
    "        ae_list.append(ae)\n",
    "\n",
    "    for ae in ae_list:\n",
    "        ae_mean_list.append(np.mean(ae))\n",
    "        ae_var_list.append(np.var(ae))\n",
    "        \n",
    "    df_dataset_sound['AE mean'] = ae_mean_list\n",
    "    df_dataset_sound['AE var'] = ae_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f64aea-d5cb-4a37-b9fd-8314540a8634",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_ae_feature(df_dataset_original)\n",
    "extract_ae_feature(df_dataset_equalized)\n",
    "extract_ae_feature(df_dataset_bandpassed)\n",
    "extract_ae_feature(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389c28d-66d4-44e7-8b3e-3379f5dcff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_denoised.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347e7d0-4638-40cc-a0ad-81e5a5298a4b",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852259ea-eff8-4459-a023-3b58ac5464c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rmse_feature(df_dataset_sound):\n",
    "    rms_list = []\n",
    "    rms_mean_list = []\n",
    "    rms_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        rms = librosa.feature.rms(sample_data, frame_length=FRAME_SIZE, hop_length=HOP_LENGTH)[0]\n",
    "        rms_list.append(rms)\n",
    "\n",
    "    for rms in rms_list:\n",
    "        rms_mean_list.append(np.mean(rms))\n",
    "        rms_var_list.append(np.var(rms))\n",
    "        \n",
    "    df_dataset_sound['RMSE mean'] = rms_mean_list\n",
    "    df_dataset_sound['RMSE var'] = rms_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17232bd2-d351-4ec0-a928-11f69a59a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_rmse_feature(df_dataset_original)\n",
    "extract_rmse_feature(df_dataset_equalized)\n",
    "extract_rmse_feature(df_dataset_bandpassed)\n",
    "extract_rmse_feature(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3717236a-7417-4a37-99e7-56bd8dfa3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_denoised.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fe90a-c6d0-412b-b305-3a6517008ab3",
   "metadata": {},
   "source": [
    "### ZCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56c375-d100-42a7-810a-7497f5461a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zcr_feature(df_dataset_sound):\n",
    "    zcr_list = []\n",
    "    zcr_mean_list = []\n",
    "    zcr_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        zcr = librosa.feature.zero_crossing_rate(sample_data, frame_length=FRAME_SIZE, hop_length=HOP_LENGTH)[0]\n",
    "        zcr_list.append(zcr)\n",
    "\n",
    "    for zcr in zcr_list:\n",
    "        zcr_mean_list.append(np.mean(zcr))\n",
    "        zcr_var_list.append(np.var(zcr))\n",
    "        \n",
    "    df_dataset_sound['ZCR mean'] = zcr_mean_list\n",
    "    df_dataset_sound['ZCR var'] = zcr_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a505a-1a62-411b-9148-682ea1609b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_zcr_feature(df_dataset_original)\n",
    "extract_zcr_feature(df_dataset_equalized)\n",
    "extract_zcr_feature(df_dataset_bandpassed)\n",
    "extract_zcr_feature(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda33c87-3d54-4e7f-b3f4-636fd08c077e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_dataset_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1fb82c-5c3d-44e7-8ace-21d722b3bf05",
   "metadata": {},
   "source": [
    "### Spectral centroid (frequency-domain feature)\n",
    "- The concentration of energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990ba32-9677-4afd-ba50-bf781a61bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "def extract_spectral_centroid(df_dataset_sound):\n",
    "    spectral_centroid_list = []\n",
    "    sc_mean_list = []\n",
    "    sc_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        sc = librosa.feature.spectral_centroid(y=sample_data, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)[0]\n",
    "        spectral_centroid_list.append(sc)\n",
    "\n",
    "    for sc in spectral_centroid_list:\n",
    "        sc_mean_list.append(np.mean(sc))\n",
    "        sc_var_list.append(np.var(sc))\n",
    "        \n",
    "    df_dataset_sound['S-centroid mean'] = sc_mean_list\n",
    "    df_dataset_sound['S-centroid var'] = sc_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b1d31-5397-4a12-b9ac-8776c24ba638",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_spectral_centroid(df_dataset_original)\n",
    "extract_spectral_centroid(df_dataset_equalized)\n",
    "extract_spectral_centroid(df_dataset_bandpassed)\n",
    "extract_spectral_centroid(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe159830-b2ee-455e-9521-61b1aad04cad",
   "metadata": {},
   "source": [
    "### Spectral bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6573bd6-b5ba-44b2-b899-1b7b2dfd704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_bandwidth(df_dataset_sound):\n",
    "    spectral_bandwidth_list = []\n",
    "    sb_mean_list = []\n",
    "    sb_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=sample_data, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH, p=2)[0]\n",
    "        spectral_bandwidth_list.append(spectral_bandwidth)\n",
    "\n",
    "    for sb in spectral_bandwidth_list:\n",
    "        sb_mean_list.append(np.mean(sb))\n",
    "        sb_var_list.append(np.var(sb))\n",
    "        \n",
    "    df_dataset_sound['S-bandwidth mean'] = sb_mean_list\n",
    "    df_dataset_sound['S-bandwidth var'] = sb_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a7583-f7cc-4d3d-9443-acdeae70b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_spectral_bandwidth(df_dataset_original)\n",
    "extract_spectral_bandwidth(df_dataset_equalized)\n",
    "extract_spectral_bandwidth(df_dataset_bandpassed)\n",
    "extract_spectral_bandwidth(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7b2f3a-17b0-4e70-b83a-0cb1945a9c7e",
   "metadata": {},
   "source": [
    "### Spectral Roll-Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778428da-f7e4-48b6-bfa5-cfbad6b4bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_rolloff(df_dataset_sound):\n",
    "    spectral_rolloff_list = []\n",
    "    rolloff_mean_list = []\n",
    "    rolloff_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=sample_data, sr=sr, roll_percent=0.85)\n",
    "        spectral_rolloff_list.append(rolloff)\n",
    "\n",
    "    for rolloff in spectral_rolloff_list:\n",
    "        rolloff_mean_list.append(np.mean(rolloff))\n",
    "        rolloff_var_list.append(np.var(rolloff))\n",
    "        \n",
    "    df_dataset_sound['Rolloff mean'] = rolloff_mean_list\n",
    "    df_dataset_sound['Rolloff var'] = rolloff_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e7dce6-7f91-43b6-9a7f-7e7c6b37033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_spectral_rolloff(df_dataset_original)\n",
    "extract_spectral_rolloff(df_dataset_equalized)\n",
    "extract_spectral_rolloff(df_dataset_bandpassed)\n",
    "extract_spectral_rolloff(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dfed8c-f5a1-4874-b75e-5856ab1c6d38",
   "metadata": {},
   "source": [
    "### BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443e27d-6549-4529-be10-0098c1338b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ber(df_dataset_sound):\n",
    "    ber_list = []\n",
    "    ber_mean_list = []\n",
    "    ber_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        Stft = librosa.stft(sample_data, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)\n",
    "        ber = feature_extractions.band_energy_ratio(Stft, split_frequency = 14000, sample_rate = sr)\n",
    "        ber_list.append(ber)\n",
    "\n",
    "    for ber in ber_list:\n",
    "        ber_mean_list.append(np.mean(ber))\n",
    "        ber_var_list.append(np.var(ber))\n",
    "        \n",
    "    df_dataset_sound['BER mean'] = ber_mean_list\n",
    "    df_dataset_sound['BER var'] = ber_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e98a12b-f5c6-45d2-81b1-fe5029a6a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_ber(df_dataset_original)\n",
    "extract_ber(df_dataset_equalized)\n",
    "extract_ber(df_dataset_bandpassed)\n",
    "extract_ber(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bf224e-33d1-4e9a-b22b-611fd2e52274",
   "metadata": {},
   "source": [
    "### Spectral Flatness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8051a7-4830-4c3d-81b5-5f30f6da981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_flatness(df_dataset_sound):\n",
    "    spectral_flatness_list = []\n",
    "    sf_mean_list = []\n",
    "    sf_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        spectral_flatness = librosa.feature.spectral_flatness(sample_data, power=2, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH)[0]\n",
    "        spectral_flatness_list.append(spectral_flatness)\n",
    "\n",
    "    for sf in spectral_flatness_list:\n",
    "        sf_mean_list.append(np.mean(sf))\n",
    "        sf_var_list.append(np.var(sf))\n",
    "        \n",
    "    df_dataset_sound['S-flatness mean'] = sf_mean_list\n",
    "    df_dataset_sound['S-flatness var'] = sf_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed2189-73d1-4c49-9791-6961427af083",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_spectral_flatness(df_dataset_original)\n",
    "extract_spectral_flatness(df_dataset_equalized)\n",
    "extract_spectral_flatness(df_dataset_bandpassed)\n",
    "extract_spectral_flatness(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e4f43-44d7-47a6-8595-29bba1108f97",
   "metadata": {},
   "source": [
    "### Spectral kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8459d16-8abf-4d54-8be1-9a7d5690e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_kurtosis(df_dataset_sound):\n",
    "    spectral_kurtosis_list = []\n",
    "    kurtosis_mean_list = []\n",
    "    kurtosis_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        S, phase = librosa.magphase(librosa.stft(sample_data))\n",
    "        # S_power = S **2   \n",
    "        S_power = S\n",
    "        s_kurtosis = feature_extractions.spectral_kurtosis(S_power)\n",
    "        spectral_kurtosis_list.append(s_kurtosis)\n",
    "\n",
    "    for sk in spectral_kurtosis_list:\n",
    "        kurtosis_mean_list.append(np.mean(sk))\n",
    "        kurtosis_var_list.append(np.var(sk))\n",
    "        \n",
    "    df_dataset_sound['S-kurtosis mean'] = kurtosis_mean_list\n",
    "    df_dataset_sound['S-kurtosis var'] = kurtosis_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e0b0c-743b-4634-9a72-2c2b7904920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_spectral_kurtosis(df_dataset_original)\n",
    "extract_spectral_kurtosis(df_dataset_equalized)\n",
    "extract_spectral_kurtosis(df_dataset_bandpassed)\n",
    "extract_spectral_kurtosis(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6878f646-a392-4325-9120-f7deeddeb838",
   "metadata": {},
   "source": [
    "### Spectral variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91978481-8d99-4d3c-b55a-f83b78cf36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_variance(df_dataset_sound):\n",
    "    spectral_variance_list = []\n",
    "    variance_mean_list = []\n",
    "    variance_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        S, phase = librosa.magphase(librosa.stft(sample_data))\n",
    "        # S_power = S **2   \n",
    "        S_power = S\n",
    "        s_variance = feature_extractions.spectral_variance(S_power)\n",
    "        spectral_variance_list.append(s_variance)\n",
    "\n",
    "    for spectral_variance in spectral_variance_list:\n",
    "        variance_mean_list.append(np.mean(spectral_variance))\n",
    "        variance_var_list.append(np.var(spectral_variance))\n",
    "        \n",
    "    df_dataset_sound['S-variance mean'] = variance_mean_list\n",
    "    df_dataset_sound['S-variance var'] = variance_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f1e2c-4802-4231-a8b1-6e1cb10ba56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_spectral_variance(df_dataset_original)\n",
    "extract_spectral_variance(df_dataset_equalized)\n",
    "extract_spectral_variance(df_dataset_bandpassed)\n",
    "extract_spectral_variance(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3d8654-b049-49e2-b597-cb345f58ba51",
   "metadata": {},
   "source": [
    "### Spectral crest factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a835a9-04e6-455a-aca3-6155e34beb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_crest(df_dataset_sound):\n",
    "    spectral_crest_list = []\n",
    "    spectral_crest_mean_list = []\n",
    "    spectral_crest_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        S, phase = librosa.magphase(librosa.stft(sample_data))\n",
    "        # S_power = S **2   \n",
    "        S_power = S\n",
    "        s_crest = feature_extractions.spectral_crest(S_power)\n",
    "        spectral_crest_list.append(s_crest)\n",
    "\n",
    "    for spectral_crest in spectral_crest_list:\n",
    "        spectral_crest_mean_list.append(np.mean(spectral_crest))\n",
    "        spectral_crest_var_list.append(np.var(spectral_crest))\n",
    "        \n",
    "    df_dataset_sound['S-crest mean'] = spectral_crest_mean_list\n",
    "    df_dataset_sound['S-crest var'] = spectral_crest_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ca0f6-0524-4da7-9083-2f6a885b3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_spectral_crest(df_dataset_original)\n",
    "extract_spectral_crest(df_dataset_equalized)\n",
    "extract_spectral_crest(df_dataset_bandpassed)\n",
    "extract_spectral_crest(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c05af-eac6-477a-be65-081ef843f089",
   "metadata": {},
   "source": [
    "### Spectral Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab20167-d018-499b-a783-9f0bdfbe8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_skewness(df_dataset_sound):\n",
    "    spectral_skewness_list = []\n",
    "    spectral_skewness_mean_list = []\n",
    "    spectral_skewness_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        S, phase = librosa.magphase(librosa.stft(sample_data))\n",
    "        # S_power = S **2   \n",
    "        S_power = S\n",
    "        s_skewness = feature_extractions.spectral_skewness(S_power)\n",
    "        spectral_skewness_list.append(s_skewness)\n",
    "\n",
    "    for spectral_skewness in spectral_skewness_list:\n",
    "        spectral_skewness_mean_list.append(np.mean(spectral_skewness))\n",
    "        spectral_skewness_var_list.append(np.var(spectral_skewness))\n",
    "        \n",
    "    df_dataset_sound['S-skewness mean'] = spectral_skewness_mean_list\n",
    "    df_dataset_sound['S-skewness var'] = spectral_skewness_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be2379-f084-4347-8a3d-ec4c7d41b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_spectral_skewness(df_dataset_original)\n",
    "extract_spectral_skewness(df_dataset_equalized)\n",
    "extract_spectral_skewness(df_dataset_bandpassed)\n",
    "extract_spectral_skewness(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ba6de-c432-4278-bc3c-b2a9f5bb0699",
   "metadata": {},
   "source": [
    "## Spectral entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd288cee-19fc-4b82-8c0f-f225798dcb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_entropy(df_dataset_sound):\n",
    "    spectral_entropy_list = []\n",
    "    spectral_entropy_mean_list = []\n",
    "    spectral_entropy_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        number_of_samples = len(sample_data)  # total number of samples\n",
    "        current_position = 0\n",
    "        count_fr = 0\n",
    "        num_fft = int(FRAME_SIZE / 2)\n",
    "        \n",
    "        s_entropy_features = []\n",
    "         # for each short-term window to end of signal\n",
    "        while current_position + FRAME_SIZE - 1 < number_of_samples:\n",
    "            count_fr += 1\n",
    "            # get current window\n",
    "            x = sample_data[current_position:current_position + FRAME_SIZE]\n",
    "\n",
    "            # update window position\n",
    "            current_position = current_position + HOP_LENGTH\n",
    "\n",
    "            # get fft magnitude\n",
    "            fft_magnitude = abs(fft(x))\n",
    "\n",
    "            # normalize fft\n",
    "            fft_magnitude = fft_magnitude[0:num_fft]\n",
    "            fft_magnitude = fft_magnitude / len(fft_magnitude)\n",
    "\n",
    "            # keep previous fft mag (used in spectral entropy)\n",
    "            if count_fr == 1:\n",
    "                fft_magnitude_previous = fft_magnitude.copy()\n",
    "\n",
    "            s_entropy = feature_extractions.spectral_entropy(fft_magnitude,n_short_blocks=10)\n",
    "            s_entropy_features.append(s_entropy)\n",
    "\n",
    "            fft_magnitude_previous = fft_magnitude.copy()\n",
    "\n",
    "        spectral_entropy_list.append(s_entropy_features)\n",
    "\n",
    "    for spectral_entropy in spectral_entropy_list:\n",
    "        spectral_entropy_mean_list.append(np.mean(spectral_entropy))\n",
    "        spectral_entropy_var_list.append(np.var(spectral_entropy))\n",
    "        \n",
    "    df_dataset_sound['S-entropy mean'] = spectral_entropy_mean_list\n",
    "    df_dataset_sound['S-entropy var'] = spectral_entropy_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e2308e-9450-4a40-ab98-52e1e8a8369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_spectral_entropy(df_dataset_original)\n",
    "extract_spectral_entropy(df_dataset_equalized)\n",
    "extract_spectral_entropy(df_dataset_bandpassed)\n",
    "extract_spectral_entropy(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec820b67-7f1a-45e6-8757-2f1570401ba2",
   "metadata": {},
   "source": [
    "### Spectral flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3bb22-bf59-4539-ae3a-5d7fa0e12ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_flux(df_dataset_sound):\n",
    "    spectral_flux_list = []\n",
    "    spectral_flux_mean_list = []\n",
    "    spectral_flux_var_list = []\n",
    "\n",
    "    for i, sample_data in enumerate(df_dataset_sound['signal']):\n",
    "        number_of_samples = len(sample_data)  # total number of samples\n",
    "        current_position = 0\n",
    "        count_fr = 0\n",
    "        num_fft = int(FRAME_SIZE / 2)\n",
    "\n",
    "        s_flux_features = []\n",
    "         # for each short-term window to end of signal\n",
    "        while current_position + FRAME_SIZE - 1 < number_of_samples:\n",
    "            count_fr += 1\n",
    "            # get current window\n",
    "            x = sample_data[current_position:current_position + FRAME_SIZE]\n",
    "\n",
    "            # update window position\n",
    "            current_position = current_position + HOP_LENGTH\n",
    "\n",
    "            # get fft magnitude\n",
    "            fft_magnitude = abs(fft(x))\n",
    "\n",
    "            # normalize fft\n",
    "            fft_magnitude = fft_magnitude[0:num_fft]\n",
    "            fft_magnitude = fft_magnitude / len(fft_magnitude)\n",
    "\n",
    "            # keep previous fft mag (used in spectral flux)\n",
    "            if count_fr == 1:\n",
    "                fft_magnitude_previous = fft_magnitude.copy()\n",
    "\n",
    "            s_flux = feature_extractions.spectral_flux(fft_magnitude,fft_magnitude_previous)\n",
    "            s_flux_features.append(s_flux)\n",
    "\n",
    "            fft_magnitude_previous = fft_magnitude.copy()\n",
    "\n",
    "        spectral_flux_list.append(s_flux_features)\n",
    "\n",
    "    for spectral_flux in spectral_flux_list:\n",
    "        spectral_flux_mean_list.append(np.mean(spectral_flux))\n",
    "        spectral_flux_var_list.append(np.var(spectral_flux))\n",
    "        \n",
    "    df_dataset_sound['S-flux mean'] = spectral_flux_mean_list\n",
    "    df_dataset_sound['S-flux var'] = spectral_flux_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5a81c-5189-4e81-b6e4-99433b0e8a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_spectral_flux(df_dataset_original)\n",
    "extract_spectral_flux(df_dataset_equalized)\n",
    "extract_spectral_flux(df_dataset_bandpassed)\n",
    "extract_spectral_flux(df_dataset_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0448b6d3-7abd-48ba-b874-6fd1dc92b2fc",
   "metadata": {},
   "source": [
    "## Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe53aa8-4281-4f41-b657-bf7ea38bfea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_denoised.groupby('Label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968168c-9f5b-48da-bec7-4917319fc1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_equalized.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44415b56-5bed-484f-9b0f-5fa41b18d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_original_selected = df_dataset_original[[ 'Label', 'label', 'AE mean', 'AE var', 'RMSE mean',\n",
    "                                                     'RMSE var', 'ZCR mean', 'ZCR var', 'Rolloff mean', 'Rolloff var',\n",
    "                                                     'BER mean', 'BER var', 'S-centroid mean', 'S-centroid var', 'S-bandwidth mean', 'S-bandwidth var',\n",
    "                                                     'S-flatness mean', 'S-flatness var', 'S-kurtosis mean', 'S-kurtosis var',\n",
    "                                                     'S-variance mean', 'S-variance var', 'S-crest mean', 'S-crest var',\n",
    "                                                     'S-skewness mean', 'S-skewness var', 'S-entropy mean', 'S-entropy var',\n",
    "                                                     'S-flux mean', 'S-flux var']]\n",
    "\n",
    "df_dataset_equalized_selected = df_dataset_equalized[[ 'Label', 'label', 'AE mean', 'AE var', 'RMSE mean',\n",
    "                                                     'RMSE var', 'ZCR mean', 'ZCR var', 'Rolloff mean', 'Rolloff var',\n",
    "                                                     'BER mean', 'BER var', 'S-centroid mean', 'S-centroid var', 'S-bandwidth mean', 'S-bandwidth var',\n",
    "                                                     'S-flatness mean', 'S-flatness var', 'S-kurtosis mean', 'S-kurtosis var',\n",
    "                                                     'S-variance mean', 'S-variance var', 'S-crest mean', 'S-crest var',\n",
    "                                                     'S-skewness mean', 'S-skewness var', 'S-entropy mean', 'S-entropy var',\n",
    "                                                     'S-flux mean', 'S-flux var']]\n",
    "\n",
    "df_dataset_bandpassed_selected = df_dataset_bandpassed[['Label', 'label', 'AE mean', 'AE var', 'RMSE mean',\n",
    "                                                     'RMSE var', 'ZCR mean', 'ZCR var', 'Rolloff mean', 'Rolloff var',\n",
    "                                                     'BER mean', 'BER var', 'S-centroid mean', 'S-centroid var', 'S-bandwidth mean', 'S-bandwidth var',\n",
    "                                                     'S-flatness mean', 'S-flatness var', 'S-kurtosis mean', 'S-kurtosis var',\n",
    "                                                     'S-variance mean', 'S-variance var', 'S-crest mean', 'S-crest var',\n",
    "                                                     'S-skewness mean', 'S-skewness var', 'S-entropy mean', 'S-entropy var',\n",
    "                                                     'S-flux mean', 'S-flux var']]\n",
    "\n",
    "df_dataset_denoised_selected = df_dataset_denoised[[ 'Label', 'label', 'AE mean', 'AE var', 'RMSE mean',\n",
    "                                                     'RMSE var', 'ZCR mean', 'ZCR var', 'Rolloff mean', 'Rolloff var',\n",
    "                                                     'BER mean', 'BER var', 'S-centroid mean', 'S-centroid var', 'S-bandwidth mean', 'S-bandwidth var',\n",
    "                                                     'S-flatness mean', 'S-flatness var', 'S-kurtosis mean', 'S-kurtosis var',\n",
    "                                                     'S-variance mean', 'S-variance var', 'S-crest mean', 'S-crest var',\n",
    "                                                     'S-skewness mean', 'S-skewness var', 'S-entropy mean', 'S-entropy var',\n",
    "                                                     'S-flux mean', 'S-flux var']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d3c40-75fd-4a49-83a8-dd44a59ce9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dataset_original['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d664d4-315a-474e-9967-ff19175f5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_dataset_equalized_selected.corr(method='spearman')\n",
    "fig, ax = plt.subplots(figsize=(20,20))         # Sample figsize in inches\n",
    "\n",
    "sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    # cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    cmap=\"plasma\",\n",
    "    square=True,\n",
    "    ax=ax,\n",
    "    annot=True,\n",
    "    cbar_kws={\"shrink\": .7},\n",
    "    linewidths=0.5, linecolor='black'\n",
    ")\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right',\n",
    "    fontsize = 16,\n",
    ")\n",
    "\n",
    "ax.set_yticklabels(\n",
    "    ax.get_yticklabels(),\n",
    "    rotation=0,\n",
    "    # horizontalalignment='right',\n",
    "    fontsize = 16\n",
    ")\n",
    "\n",
    "ax.axhline(y=0, color='k',linewidth=4)\n",
    "ax.axhline(y=corr.shape[1], color='k',linewidth=4)\n",
    "ax.axvline(x=0, color='k',linewidth=4)\n",
    "ax.axvline(x=corr.shape[0], color='k',linewidth=4)\n",
    "\n",
    "save_fig(\"correlation matrix (equalized) - layerwise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05be83a-9a27-419f-b056-80753f90e93f",
   "metadata": {},
   "source": [
    "## Constructing labels and input features for training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a2fb5-f73d-44cf-b179-149ef2ccdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected_list = ['AE mean', 'AE var', 'RMSE mean',\n",
    "                         'RMSE var', 'ZCR mean', 'ZCR var', 'Rolloff mean', 'Rolloff var',\n",
    "                         'BER mean', 'BER var', 'S-centroid mean', 'S-centroid var', 'S-bandwidth mean', 'S-bandwidth var',\n",
    "                         'S-flatness mean', 'S-flatness var', 'S-kurtosis mean', 'S-kurtosis var',\n",
    "                         'S-variance mean', 'S-variance var', 'S-crest mean', 'S-crest var',\n",
    "                         'S-skewness mean', 'S-skewness var', 'S-entropy mean', 'S-entropy var',\n",
    "                         'S-flux mean', 'S-flux var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34edf52a-fb0b-409b-86d1-f995fc792266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label = df_dataset_original_500_selected['Label'].to_list()\n",
    "y_original = df_dataset_original_selected['label'].to_list()\n",
    "X_original = df_dataset_original_selected[feature_selected_list].to_numpy()\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "y_equalized = df_dataset_equalized_selected['label'].to_list()\n",
    "X_equalized = df_dataset_equalized_selected[feature_selected_list].to_numpy()\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "y_bandpassed = df_dataset_bandpassed_selected['label'].to_list()\n",
    "X_bandpassed = df_dataset_bandpassed_selected[feature_selected_list].to_numpy()\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "y_denoised = df_dataset_denoised_selected['label'].to_list()\n",
    "X_denoised = df_dataset_denoised_selected[feature_selected_list].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74edaf-f35d-4d34-90a3-77ec974c4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import gca\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (4,3), dpi = 600)\n",
    "widths = 2\n",
    "ax = gca()\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(widths)\n",
    "\n",
    "    tick_width = 1.5\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(df_dataset_denoised_selected[feature_selected_list], y_original)\n",
    "\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=df_dataset_denoised_selected[feature_selected_list].columns)\n",
    "\n",
    "\n",
    "color=['red', 'blue','yellow','green', 'steelblue','orange', 'olive', 'midnightblue', 'darkkhaki', \n",
    "       \"lightblue\", \"purple\", \"darkred\", \"gray\", \"black\", \"lightyellow\"] #'darkkhaki'\n",
    "\n",
    "feat_importances.nlargest(15).plot(kind='barh', color = color,edgecolor='k', linewidth =0.5)\n",
    "plt.title(\"RF Feature importance\",  fontsize = 12, y=1.02)\n",
    "plt.xlabel('Relative importance', fontsize = 12, labelpad = 2)\n",
    "plt.tick_params(axis='both', labelsize=8, pad = 3)\n",
    "# plt.xaxis.set_tick_params(pad=1)\n",
    "# plt.ylabel(fontsize = 14, labelpad = 5)\n",
    "\n",
    "# plt.show()\n",
    "save_fig(\"feature_importance (denoised) layerwise\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7766d-4d7d-498f-94ce-b3d53541fd63",
   "metadata": {},
   "source": [
    "### Final selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1afd1b-54eb-4663-b077-488c0963e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected_list = ['label', 'S-bandwidth mean', 'S-entropy mean','S-flatness mean', 'S-variance mean', 'S-centroid var',\n",
    "                        \"RMSE mean\",'S-centroid mean','AE mean', \n",
    "                         'S-flux mean','ZCR mean'] \n",
    "                         # 'S-skewness mean','S-kurtosis mean', 'Energy entropy mean',\n",
    "                         # 'S-entropy var', 'S-variance var'\n",
    "        \n",
    "# feature_selected_list = ['AE mean', 'S-bandwidth mean', 'S-Flatness mean',\"RMSE var\",\n",
    "#                          'S-crest mean','S-variance mean','AE var', 'S-flux mean', 'S-entropy mean',\n",
    "#                          'S-centroid var', 'S-skewness mean','S-kurtosis mean', 'Energy entropy var',\n",
    "#                          'S-entropy var', 'S-variance var'] \n",
    "\n",
    "df_dataset_original_selected_final = df_dataset_original_selected[feature_selected_list]\n",
    "df_dataset_equalized_selected_final = df_dataset_equalized_selected[feature_selected_list]\n",
    "df_dataset_bandpassed_selected_final = df_dataset_bandpassed_selected[feature_selected_list]\n",
    "df_dataset_denoised_selected_final = df_dataset_denoised_selected[feature_selected_list]\n",
    "\n",
    "\n",
    "\n",
    "X_original = df_dataset_original_selected_final[feature_selected_list].to_numpy()\n",
    "#----------------------------------------------------------------------------\n",
    "X_equalized = df_dataset_equalized_selected_final[feature_selected_list].to_numpy()\n",
    "#----------------------------------------------------------------------------\n",
    "X_bandpassed = df_dataset_bandpassed_selected_final[feature_selected_list].to_numpy()\n",
    "#----------------------------------------------------------------------------\n",
    "X_denoised = df_dataset_denoised_selected_final[feature_selected_list].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69105fe-aa58-495a-86e5-521c1d8faf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_dataset_original_selected_final.corr(method='spearman')\n",
    "fig, ax = plt.subplots(figsize=(10,10))         # Sample figsize in inches\n",
    "\n",
    "sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    # cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    cmap=\"plasma\",\n",
    "    square=True,\n",
    "    ax=ax,\n",
    "    annot=True,\n",
    "    annot_kws={\"size\":12},\n",
    "    cbar_kws={\"shrink\": .7,\n",
    "             \"ticks\": [-1,-0.5, 0,0.5, 1]},\n",
    "    fmt='.2f',\n",
    "    linewidths=0.5, linecolor='white'\n",
    ")\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right',\n",
    "    fontsize = 16,\n",
    ")\n",
    "\n",
    "ax.set_yticklabels(\n",
    "    ax.get_yticklabels(),\n",
    "    rotation=0,\n",
    "    # horizontalalignment='right',\n",
    "    fontsize = 16\n",
    ")\n",
    "\n",
    "ax.set_title(\"Spearman feature correlation matrix\", fontsize = 24, pad = 16)\n",
    "ax.axhline(y=0, color='k',linewidth=3)\n",
    "ax.axhline(y=corr.shape[1], color='k',linewidth=3)\n",
    "ax.axvline(x=0, color='k',linewidth=3)\n",
    "ax.axvline(x=corr.shape[0], color='k',linewidth=3)\n",
    "\n",
    "save_fig(\"correlation matrix (raw) - layerwise selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a7a57-8ff0-4418-a86e-57fa77fe8879",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_original_selected.to_csv('..\\\\outputs\\\\June_experiments\\\\layer_prediction\\\\df_dataset_original.csv', index = False, mode='a')\n",
    "df_dataset_equalized_selected.to_csv('..\\\\outputs\\\\June_experiments\\\\layer_prediction\\\\df_dataset_equalized.csv', index = False, mode='a')\n",
    "df_dataset_bandpassed_selected.to_csv('..\\\\outputs\\\\June_experiments\\\\layer_prediction\\\\df_dataset_bandpassed.csv', index = False, mode='a')\n",
    "df_dataset_denoised_selected.to_csv('..\\\\outputs\\\\June_experiments\\\\layer_prediction\\\\df_dataset_denoised.csv', index = False, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b012f1-0487-458f-b917-732380dbe5ef",
   "metadata": {},
   "source": [
    "## Data-pre processing, cleaning, unsupervised learning\n",
    "\n",
    "#### Data Standarization (zero mean and unit variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d442b-ef1b-4246-8231-3e965aa4bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # normalize the data before applying the fit method\n",
    "df_original_normalized=(df_dataset_original_selected.select_dtypes(include=np.number) - df_dataset_original_selected.mean(numeric_only = True)) / df_dataset_original_selected.std(numeric_only = True)\n",
    "df_equalized_normalized=(df_dataset_equalized_selected.select_dtypes(include=np.number) - df_dataset_equalized_selected.mean(numeric_only = True)) / df_dataset_equalized_selected.std(numeric_only = True)\n",
    "df_bandpassed_normalized=(df_dataset_bandpassed_selected.select_dtypes(include=np.number) - df_dataset_bandpassed_selected.mean(numeric_only = True)) / df_dataset_bandpassed_selected.std(numeric_only = True)\n",
    "df_denoised_normalized=(df_dataset_denoised_selected.select_dtypes(include=np.number) - df_dataset_denoised_selected.mean(numeric_only = True)) / df_dataset_denoised_selected.std(numeric_only = True)\n",
    "# ## note that if using Sklearn preprocessing function, the dataframe will be converted to numpy array\n",
    "\n",
    "# df_original_normalized = df_original_normalized.join(df_dataset_original_selected[\"Label\"])\n",
    "# df_equalized_normalized = df_equalized_normalized.join(df_dataset_equalized_selected[\"Label\"])\n",
    "# df_bandpassed_normalized = df_bandpassed_normalized.join(df_dataset_bandpassed_selected[\"Label\"])\n",
    "# df_denoised_normalized = df_denoised_normalized.join(df_dataset_denoised_selected[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de6942-b83b-4681-b43f-51a3d7e232d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ecbed-db14-4c71-a61e-13bf8ed2fefb",
   "metadata": {},
   "source": [
    "## Principal component analsis (PCA)\n",
    "- reference1: https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64710297-1e6c-4dcf-9a35-997c90fb5a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# dimensionality reduction with 18 features\n",
    "pca= PCA()\n",
    "pca.fit(df_denoised_normalized)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efaed78-4aa5-41a9-bed2-f47e8009ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine explained variance using explained_variance_ration_ attribute\n",
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "\n",
    "# Cumulative sum of eigenvalues; This will be used to create step plot\n",
    "# for visualizing the variance explained by each principal component.\n",
    "\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "#\n",
    "# Create the visualization plot\n",
    "\n",
    "plt.figure(figsize=(8, 5)) \n",
    "plt.grid(linestyle='--', linewidth=1, alpha=0.7)\n",
    "plt.title(\"Denoised acoustic signal feature\", fontsize = 20, pad = 12)\n",
    "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=1.0, align='center', label='Individual explained variance')\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio', fontsize = 18, labelpad=12)\n",
    "plt.xlabel('Principal component index', fontsize = 18, labelpad=12)\n",
    "plt.legend(loc='best', fontsize=\"large\")\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "save_fig('PCA_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5152f7-5f0e-4cac-99f6-4e52c5304b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_explained_variance_ratio (df_signal_feature, name):\n",
    "    pca= PCA()\n",
    "    pca.fit(df_signal_feature)\n",
    "    # print(pca.explained_variance_ratio_)\n",
    "    exp_var_pca = pca.explained_variance_ratio_\n",
    "    cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "    \n",
    "    plt.figure(figsize=(8, 5)) \n",
    "    plt.grid(linestyle='--', linewidth=1, alpha=0.7)\n",
    "    plt.title(name + \" acoustic signal feature\", fontsize = 20, pad = 12)\n",
    "    plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=1.0, align='center', label='Individual explained variance')\n",
    "    plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio', fontsize = 18, labelpad=12)\n",
    "    plt.xlabel('Principal component index', fontsize = 18, labelpad=12)\n",
    "    plt.legend(loc='best', fontsize=\"large\")\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    save_fig(\"PCA_\" + name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83123c9-73cd-4a04-b3a9-20eb3bfdea1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_pca_explained_variance_ratio(df_original_normalized, \"Raw\")\n",
    "plot_pca_explained_variance_ratio(df_equalized_normalized, \"Equalized\")\n",
    "plot_pca_explained_variance_ratio(df_bandpassed_normalized, \"Bandpassed\")\n",
    "plot_pca_explained_variance_ratio(df_denoised_normalized, \"Denoised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3480b70-e889-475b-b326-444387cf3ca5",
   "metadata": {},
   "source": [
    "### Only top 10 principle component are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4774c-944a-4308-b3ed-0a6e5a02da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches\n",
    "    \n",
    "def two_d_pca_projection (df_normalized, name):\n",
    "    pca_2 = PCA(n_components=2)\n",
    "    pca_2.fit(df_normalized)\n",
    "    # dimensionality reduction -> output is reduced feature space\n",
    "    data_pca_2 = pca_2.transform(df_normalized)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    levels, categories = pd.factorize(df_dataset_original_selected['Label'])\n",
    "    colors = [plt.cm.tab10(i) for i in levels] # using the \"tab10\" colormap\n",
    "    handles = [matplotlib.patches.Patch(color=plt.cm.tab10(i), label=c) for i, c in enumerate(categories)]\n",
    "\n",
    "    xdata = data_pca_2[:, 0]\n",
    "    ydata = data_pca_2[:, 1]\n",
    "\n",
    "    plt.scatter(xdata, ydata, c=colors)\n",
    "    plt.xlabel('Principal component 1',fontsize=20, labelpad=13)\n",
    "    plt.ylabel('Principal component 2',fontsize=20, labelpad=13)\n",
    "    plt.title('PCA Projection ' + name,fontsize=20, pad=12)\n",
    "    # plt.gca().set(xlabel='Principle component 1', ylabel='Principle component 2', title='PCA dimensionality reduction', set_fontsize=12)\n",
    "    plt.legend(handles=handles, loc='upper left', fontsize='large') # title='Color'\n",
    "    save_fig(\"PCA_2D_\" + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4460e4-34ba-42b9-aa3f-44942423f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_d_pca_projection(df_bandpassed_normalized, \"bandpassed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0b2db-5a1a-4aa1-9253-6a4575224f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_d_pca_projection (df_normalized, name):\n",
    "    pca_3 = PCA(n_components=3)\n",
    "    pca_3.fit(df_normalized)\n",
    "    # dimensionality reduction -> output is reduced feature space\n",
    "    data_pca_3 = pca_3.transform(df_normalized)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    levels, categories = pd.factorize(df_dataset_original_selected['Label'])\n",
    "    colors = [plt.cm.tab10(i) for i in levels] # using the \"tab10\" colormap\n",
    "    handles = [matplotlib.patches.Patch(color=plt.cm.tab10(i), label=c) for i, c in enumerate(categories)]\n",
    "\n",
    "\n",
    "    # Data for three-dimensional scattered points\n",
    "    xdata = data_pca_3[:, 1]\n",
    "    ydata = data_pca_3[:, 2]\n",
    "    zdata = data_pca_3[:, 0]\n",
    "    # ax.scatter3D(xdata, ydata, zdata,\n",
    "    #              c=df_denoised_normalized[\"laser power\"], edgecolor='none', alpha=0.9, s=40,\n",
    "    #              cmap=plt.cm.get_cmap('Set1', 4)); # cmap='Greens'\n",
    "\n",
    "    ax.scatter3D(xdata, ydata, zdata,edgecolor='none', alpha=1, s=90,\n",
    "                 c=colors); # cmap='Greens'\n",
    "\n",
    "    ax.set_xlabel('Principal component 1',fontsize=16, labelpad=13)\n",
    "    ax.set_ylabel('Principal component 2',fontsize=16, labelpad=13)\n",
    "    ax.set_zlabel('Principal component 3',fontsize=16, labelpad=13)\n",
    "    ax.set_title(\"PCA 3D projection \" + name, fontsize = 20, pad = 5)\n",
    "    # plt.colorbar();\n",
    "    plt.legend(handles=handles, loc='best', fontsize='large') #; upper left # title='Color'\n",
    "    save_fig(\"PCA_3D_\" + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c1907-7b74-477c-b3c4-9d22e88abbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_d_pca_projection(df_equalized_normalized, \"(equalized)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135adfbf-7ffb-4a61-8950-7b40d57e99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# boston = load_boston()\n",
    "# df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "n_components = 10\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(df_denoised_normalized)\n",
    "# dimensionality reduction -> output is reduced feature space\n",
    "data_pca = pca.transform(df_denoised_normalized)\n",
    "\n",
    "total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "\n",
    "labels = {str(i): f\"PC {i+1}\" for i in range(n_components)}\n",
    "labels['color'] = 'Experiment number' ## will be modified \n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    data_pca, # components\n",
    "    # color=boston.target,\n",
    "    color = df_dataset_original_selected[\"Label\"],\n",
    "    symbol = df_dataset_original_selected[\"Label\"],\n",
    "    dimensions=range(n_components),\n",
    "    labels=labels,\n",
    "    title=f'Total Explained Variance: {total_var:.2f}%',\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    font=dict(\n",
    "        family=\"Arial\", #\"Courier New, monospace\"\n",
    "        size=16,\n",
    "        color=\"black\"\n",
    "    ),\n",
    "\n",
    ")\n",
    "\n",
    "fig.update_traces(diagonal_visible=True)\n",
    "# fig.show()\n",
    "# fig.write_image(\"images/scatterogram_PCA10.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
